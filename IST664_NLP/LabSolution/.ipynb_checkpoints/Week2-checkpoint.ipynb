{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week2 Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated in the lab session:\n",
    "<br><br>\n",
    "Choose a file that you want to work on—either one of the files from the book corpus or one from the Gutenberg corpus.\n",
    "<br><br>\n",
    "Make a bigram finder and experiment with whether to apply the filters or not. Run the scoring with both the raw frequency and the pmi scorers and compare results.\n",
    "<br><br>\n",
    "To complete the exercise, choose one of your top 20 frequency lists to report to show to the class. Write an introductory sentence or paragraph telling what text you chose and what bigram filters and scorer you used. Put this and the frequency list in your response. You may check out the frequency lists of other corpora by other students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/erm1000255241/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/erm1000255241/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austen-persuasion.txt\n",
      "466292\n",
      "[Persuasion by Jane Austen 1818]\n",
      "\n",
      "\n",
      "Chapter 1\n",
      "\n",
      "\n",
      "Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who,\n",
      "for\n"
     ]
    }
   ],
   "source": [
    "# Week 2:  Bigram Frequencies and Mutual Information\n",
    "# This file has small examples that are meant to be run individually\n",
    "#   in the Python interpreter or jupyter notebook cells\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "# You can then view some books obtained from the Gutenberg on-line book project:\n",
    "nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "# For purposes of this lab, we will work with the first book, Jane Austen’s “Emma”.  First, we save the first fileid (number 0 in the list) into a variable named file0 so that we can reuse it:\n",
    "\n",
    "file0 = nltk.corpus.gutenberg.fileids( ) [1]\n",
    "print(file0)\n",
    "\n",
    "# We can get the original text, using the raw function.  This returns the text as a string of characters, and the length function tells us how many characters.\n",
    "emmatext = nltk.corpus.gutenberg.raw(file0)\n",
    "print(len(emmatext))\n",
    "\n",
    "# Since this is quite long, we can view part of it, e.g. the first 120 characters\n",
    "print(emmatext[:120])\n",
    "\n",
    "# Processing Text\n",
    "\n",
    "# NLTK has several tokenizers available to break the raw text into tokens; we will use one trained on news articles that separates by white space and by special characters (punctuation), but also leaves together some of these such as Mr.:\n",
    "emmatokens = nltk.word_tokenize(emmatext)\n",
    "\n",
    "emmawords = [w.lower( ) for w in emmatokens] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a frequency distribution of words\n",
    "ndist = FreqDist(emmawords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", \t 7024\n",
      "the \t 3328\n",
      ". \t 3119\n",
      "and \t 2786\n",
      "to \t 2782\n"
     ]
    }
   ],
   "source": [
    "# print the top 30 tokens by frequency\n",
    "nitems = ndist.most_common(5)\n",
    "for item in nitems:\n",
    "    print (item[0], '\\t', item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'persuasion', 'by', 'jane', 'austen']\n",
      "[('[', 'persuasion'), ('persuasion', 'by'), ('by', 'jane'), ('jane', 'austen'), ('austen', '1818')]\n"
     ]
    }
   ],
   "source": [
    "# Bigrams and Bigram frequency distribution\n",
    "emmabigrams = list(nltk.bigrams(emmawords))\n",
    "print(emmawords[:5])\n",
    "print(emmabigrams[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for bigrams and bigram measures\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finder 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder = BigramCollocationFinder.from_words(emmawords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tuple'>\n",
      "((',', 'and'), 0.012939133986928104)\n"
     ]
    }
   ],
   "source": [
    "# scored is a list of bigram pairs with their score\n",
    "print(type(scored))\n",
    "first = scored[0]\n",
    "print(type(first))\n",
    "print(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and'), 0.012939133986928104)\n",
      "((';', 'and'), 0.0048304738562091505)\n",
      "(('of', 'the'), 0.004340277777777778)\n",
      "(('to', 'be'), 0.003860294117647059)\n",
      "(('.', \"''\"), 0.0037683823529411765)\n"
     ]
    }
   ],
   "source": [
    "# scores are sorted in decreasing frequency\n",
    "for bscore in scored[:5]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the'), 0.004340277777777778)\n",
      "(('to', 'be'), 0.003860294117647059)\n",
      "(('in', 'the'), 0.003278186274509804)\n",
      "(('had', 'been'), 0.002593954248366013)\n",
      "(('she', 'had'), 0.002318218954248366)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder.apply_word_filter(alpha_filter)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:5]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('captain', 'wentworth'), 0.001991421568627451)\n",
      "(('mr', 'elliot'), 0.0017565359477124183)\n",
      "(('lady', 'russell'), 0.0015012254901960785)\n",
      "(('sir', 'walter'), 0.0013174019607843138)\n",
      "(('mrs', 'clay'), 0.0006638071895424837)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove stop words\n",
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:5]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finder 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and'), 0.012939133986928104)\n",
      "((';', 'and'), 0.0048304738562091505)\n",
      "(('of', 'the'), 0.004340277777777778)\n",
      "(('to', 'be'), 0.003860294117647059)\n",
      "(('.', \"''\"), 0.0037683823529411765)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter (on a new finder) to remove low frequency words\n",
    "finder2 = BigramCollocationFinder.from_words(emmawords)\n",
    "finder2.apply_freq_filter(2)\n",
    "scored = finder2.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:5]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the'), 0.004340277777777778)\n",
      "(('to', 'be'), 0.003860294117647059)\n",
      "(('in', 'the'), 0.003278186274509804)\n",
      "(('had', 'been'), 0.002593954248366013)\n",
      "((\"''\", '``'), 0.002573529411764706)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter on both words of the ngram\n",
    "finder2.apply_ngram_filter(lambda w1, w2: len(w1) < 2)\n",
    "scored = finder2.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:5]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finder 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('1818', ']'), 16.579315937580013)\n",
      "(('a.', 'e.'), 16.579315937580013)\n",
      "(('accustomary', 'intervention'), 16.579315937580013)\n",
      "(('anyone', 'intending'), 16.579315937580013)\n",
      "(('apples', 'stolen'), 16.579315937580013)\n"
     ]
    }
   ],
   "source": [
    "### pointwise mutual information\n",
    "finder3 = BigramCollocationFinder.from_words(emmawords)\n",
    "scored = finder3.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:5]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('west', 'indies'), 13.508926609688618)\n",
      "(('dr', 'shirley'), 12.935459747805288)\n",
      "(('marlborough', 'buildings'), 12.672425341971497)\n",
      "(('westgate', 'buildings'), 12.672425341971497)\n",
      "(('milsom', 'street'), 11.878876219438924)\n",
      "(('colonel', 'wallis'), 11.491853096329676)\n",
      "(('eldest', 'son'), 11.316281531746222)\n",
      "(('five', 'minutes'), 11.293913718717766)\n",
      "(('poor', 'richard'), 10.797956224055355)\n",
      "(('ten', 'minutes'), 10.61584181360513)\n"
     ]
    }
   ],
   "source": [
    "# to get good results, must first apply frequency filter\n",
    "finder.apply_freq_filter(5)\n",
    "scored = finder.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:10]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Solution by ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('captain', 'wentworth'), 0.001991421568627451)\n",
      "(('mr', 'elliot'), 0.0017565359477124183)\n",
      "(('lady', 'russell'), 0.0015012254901960785)\n",
      "(('sir', 'walter'), 0.0013174019607843138)\n",
      "(('mrs', 'clay'), 0.0006638071895424837)\n",
      "(('mrs', 'musgrove'), 0.0006638071895424837)\n",
      "(('mrs', 'smith'), 0.00065359477124183)\n",
      "(('captain', 'benwick'), 0.0005616830065359477)\n",
      "(('miss', 'elliot'), 0.0004901960784313725)\n",
      "(('mrs', 'croft'), 0.00041870915032679736)\n",
      "(('captain', 'harville'), 0.000377859477124183)\n",
      "(('great', 'deal'), 0.00034722222222222224)\n",
      "(('charles', 'hayter'), 0.0003370098039215686)\n",
      "(('camden', 'place'), 0.0002961601307189542)\n",
      "(('mr', 'shepherd'), 0.00026552287581699344)\n",
      "(('kellynch', 'hall'), 0.0002553104575163399)\n",
      "(('lady', 'dalrymple'), 0.0002553104575163399)\n",
      "(('mrs', 'harville'), 0.00024509803921568627)\n",
      "(('anne', 'elliot'), 0.00023488562091503269)\n",
      "(('colonel', 'wallis'), 0.00023488562091503269)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter (on a new finder) to remove low frequency words\n",
    "finder_opt = BigramCollocationFinder.from_words(emmawords)\n",
    "finder_opt.apply_word_filter(alpha_filter)\n",
    "finder_opt.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder_opt.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('west', 'indies'), 13.508926609688618)\n",
      "(('dr', 'shirley'), 12.935459747805288)\n",
      "(('marlborough', 'buildings'), 12.672425341971497)\n",
      "(('westgate', 'buildings'), 12.672425341971497)\n",
      "(('milsom', 'street'), 11.878876219438924)\n",
      "(('colonel', 'wallis'), 11.491853096329676)\n",
      "(('eldest', 'son'), 11.316281531746222)\n",
      "(('five', 'minutes'), 11.293913718717766)\n",
      "(('poor', 'richard'), 10.797956224055355)\n",
      "(('ten', 'minutes'), 10.61584181360513)\n",
      "(('eight', 'years'), 10.399406847565078)\n",
      "(('kellynch', 'hall'), 10.225992646417119)\n",
      "(('camden', 'place'), 10.169925001442312)\n",
      "(('laura', 'place'), 10.169925001442312)\n",
      "(('depend', 'upon'), 9.949959317500403)\n",
      "(('dare', 'say'), 9.79914902696819)\n",
      "(('anybody', 'else'), 9.75403910752515)\n",
      "(('miss', 'carteret'), 9.613531652917928)\n",
      "(('years', 'ago'), 9.306297443173598)\n",
      "(('sir', 'walter'), 9.2524335998176)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter (on a new finder) to remove low frequency words\n",
    "finder_opt2 = BigramCollocationFinder.from_words(emmawords)\n",
    "finder_opt2.apply_freq_filter(5)\n",
    "finder_opt2.apply_word_filter(alpha_filter)\n",
    "finder_opt2.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder_opt2.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
