{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/erm1000255241/Library/Mobile Documents/com~apple~CloudDocs/Documents/SyracuseUniversity/5th_Quarter/IST664 /LabSolution'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/erm1000255241/Library/Mobile Documents/com~apple~CloudDocs/Documents/SyracuseUniversity/5th_Quarter/IST664 /LabWeek3/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"Mr. Black and Mrs. Brown attended the lecture by Dr. Gray, but Gov. White wasn't there.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mr. Black and Mrs. Brown attended the lecture by Dr. Gray, but Gov. White wasn't there.\""
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'''(?x)\n",
    "        (?:[A-Z]\\.)+\n",
    "        | \\$?\\d+(?:\\.\\d+)?%?\n",
    "        | \\w+(?:-\\w+)*\n",
    "        | \\.\\.\\.\n",
    "        | [][.,;\"'?():-_%#']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr', '.', 'Black', 'and', 'Mrs', '.', 'Brown', 'attended', 'the', 'lecture', 'by', 'Dr', '.', 'Gray', ',', 'but', 'Gov', '.', 'White', 'wasn', \"'\", 't', 'there', '.']\n"
     ]
    }
   ],
   "source": [
    "tkns = nltk.regexp_tokenize(txt, pattern)\n",
    "print(tkns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'''(?x)\n",
    "        (?:[A-Z]\\.)+\n",
    "        | \\w+(?:.)b*\n",
    "        | \\$?\\d+(?:\\.\\d+)?%?\n",
    "        | \\w+(?:-\\w+)*\n",
    "        | \\.\\.\\.\n",
    "        | [][.,;\"'?():-_%#']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.', 'Black ', 'and ', 'Mrs.', 'Brown ', 'attended ', 'the ', 'lecture b', 'y ', 'Dr.', 'Gray,', 'but ', 'Gov.', 'White ', \"wasn'\", 't ', 'there.']\n"
     ]
    }
   ],
   "source": [
    "tkns = nltk.regexp_tokenize(txt, pattern)\n",
    "print(tkns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'''(?x)\n",
    "        (?:[A-Z]\\.)+\n",
    "        | \\$?\\d+(?:\\.\\d+)?%?\n",
    "        | \\w+(?:.)b*\n",
    "        | \\w+(?:-\\w+)*\n",
    "        | \\.\\.\\.\n",
    "        | [][.,;\"'?():-_%#']\n",
    "        | [A-Z](?:[a-z]\\.)+.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.', 'Black ', 'and ', 'Mrs.', 'Brown ', 'attended ', 'the ', 'lecture b', 'y ', 'Dr.', 'Gray,', 'but ', 'Gov.', 'White ', \"wasn'\", 't ', 'there.']\n"
     ]
    }
   ],
   "source": [
    "tkns = nltk.regexp_tokenize(txt, pattern)\n",
    "print(tkns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'''(?x)\n",
    "        (?:[A-Z]\\.)+\n",
    "        | \\$?\\d+(?:\\.\\d+)?%?\n",
    "        | \\w+(?:-\\w+)*\n",
    "        | \\.\\.\\.\n",
    "        | [][.,;\"'?():-_%#']\n",
    "        | [A-Z](?:[a-z]\\.)+.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = pattern + ' |' + pattern1[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = pattern + ' |' + pattern2[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkns = nltk.regexp_tokenize(txt, pattern)\n",
    "print(tkns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr.',\n",
       " 'Black',\n",
       " 'and',\n",
       " 'Mrs.',\n",
       " 'Brown',\n",
       " 'attended',\n",
       " 'the',\n",
       " 'lecture',\n",
       " 'by',\n",
       " 'Dr.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'calgarian', 'have', 'found', 'a', 'rather', 'unusu', 'way', 'of', 'leav', 'snow', 'and', 'ice', 'behind', '.', 'they', 'set', 'off', 'thi', 'week', 'on', 'foot', 'and', 'by', 'camel', 'on', 'a', 'gruel', 'trek', 'across', 'the', 'burn', 'arabian', 'desert', '.', 'when', 'they', 'were', 'still', 'in', 'canada', ',', 'plan', 'their', 'trip', ',', 'they', 'expect', 'they', 'would', 'feel', 'lone', '.', 'but', 'after', 'two', 'day', 'into', 'the', '1,200', 'kilometr', 'journey', ',', 'the', 'caravan', 'ha', 'won', 'celebr', 'statu', 'among', 'the', 'nativ', 'bedouin', 'peopl', 'and', 'govern', 'offici', 'of', 'oman', '.', 'some', 'have', 'excitedli', 'tag', 'along', ',', 'say', 'expedit', 'leader', 'jami', 'clark', '.', 'mr.', 'clark', 'is', 'make', 'the', 'trek', 'with', 'hi', 'older', 'brother', 'leigh', 'and', 'their', 'friend', 'bruce', 'kirbi', '.', 'they', 'have', 'hire', 'three', 'guid', '.', 'they', 'are', 'now', 'in', 'the', 'omani', 'citi', 'of', 'solalah', 'on', 'the', 'arabian', 'sea', '.', 'the', 'group', 'wa', 'forc', 'to', 'return', 'briefli', 'to', 'replac', 'some', 'broken', 'equip', ',', 'notabl', 'camel', 'saddl', ',', '40', 'kilometr', 'into', 'the', 'odyssey', '.', 'the', 'adventur', 'expect', 'to', 'travel', 'for', 'up', 'to', '55', 'day', 'through', 'the', 'scorch', 'heat', 'and', 'tower', 'dune', 'of', 'oman', ',', 'saudi', 'arabia', 'and', 'the', 'unit', 'arab', 'emir', '.', 'they', 'are', 'attempt', 'to', 'becom', 'the', 'first', 'western', 'in', 'more', 'than', '50', 'year', 'to', 'cross', 'the', 'empti', 'quarter', 'of', 'arabia']\n"
     ]
    }
   ],
   "source": [
    "tksPstem = [porter.stem(t) for t in tokens]\n",
    "print(tksPstem[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'calg', 'hav', 'found', 'a', 'rath', 'unus', 'way', 'of', 'leav', 'snow', 'and', 'ic', 'behind', '.', 'they', 'set', 'off', 'thi', 'week', 'on', 'foot', 'and', 'by', 'camel', 'on', 'a', 'gruel', 'trek', 'across', 'the', 'burn', 'arab', 'desert', '.', 'when', 'they', 'wer', 'stil', 'in', 'canad', ',', 'plan', 'their', 'trip', ',', 'they', 'expect', 'they', 'would', 'feel', 'lon', '.', 'but', 'aft', 'two', 'day', 'into', 'the', '1,200', 'kilomet', 'journey', ',', 'the', 'carav', 'has', 'won', 'celebr', 'stat', 'among', 'the', 'nat', 'bedouin', 'peopl', 'and', 'govern', 'off', 'of', 'om', '.', 'som', 'hav', 'excit', 'tag', 'along', ',', 'say', 'expedit', 'lead', 'jamy', 'clark', '.', 'mr.', 'clark', 'is', 'mak', 'the', 'trek', 'with', 'his', 'old', 'broth', 'leigh', 'and', 'their', 'friend', 'bruc', 'kirby', '.', 'they', 'hav', 'hir', 'three', 'guid', '.', 'they', 'ar', 'now', 'in', 'the', 'oman', 'city', 'of', 'solalah', 'on', 'the', 'arab', 'sea', '.', 'the', 'group', 'was', 'forc', 'to', 'return', 'brief', 'to', 'replac', 'som', 'brok', 'equip', ',', 'not', 'camel', 'saddl', ',', '40', 'kilomet', 'into', 'the', 'odyssey', '.', 'the', 'adv', 'expect', 'to', 'travel', 'for', 'up', 'to', '55', 'day', 'through', 'the', 'scorch', 'heat', 'and', 'tow', 'dun', 'of', 'om', ',', 'saud', 'arab', 'and', 'the', 'unit', 'arab', 'emir', '.', 'they', 'ar', 'attempt', 'to', 'becom', 'the', 'first', 'western', 'in', 'mor', 'than', '50', 'year', 'to', 'cross', 'the', 'empty', 'quart', 'of', 'arab']\n"
     ]
    }
   ],
   "source": [
    "tksLstem = [lancaster.stem(t) for t in tokens]\n",
    "print(tksLstem[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350\n"
     ]
    }
   ],
   "source": [
    "n = random.randrange(0,1363)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'poison'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tksPstem[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'poison'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tksLstem[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
