{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week2 Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated in the lab session:\n",
    "<br><br>\n",
    "Choose a file that you want to work onâ€”either one of the files from the book corpus or one from the Gutenberg corpus.\n",
    "<br><br>\n",
    "Make a bigram finder and experiment with whether to apply the filters or not. Run the scoring with both the raw frequency and the pmi scorers and compare results.\n",
    "<br><br>\n",
    "To complete the exercise, choose one of your top 20 frequency lists to report to show to the class. Write an introductory sentence or paragraph telling what text you chose and what bigram filters and scorer you used. Put this and the frequency list in your response. You may check out the frequency lists of other corpora by other students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for bigrams and bigram measures\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ramosem/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/ramosem/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_filter(w):\n",
    "#pattern to match a word of non-alphabetical characters\n",
    "    pattern\t=re.compile('^[^a-z]+$')\n",
    "    if(pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakespeare-hamlet.txt\n"
     ]
    }
   ],
   "source": [
    "file1 = nltk.corpus.gutenberg.fileids( )[15]\n",
    "print(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162881\n"
     ]
    }
   ],
   "source": [
    "emmatext1 = nltk.corpus.gutenberg.raw(file1)\n",
    "print(len(emmatext1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakespeare-caesar.txt\n"
     ]
    }
   ],
   "source": [
    "file2 = nltk.corpus.gutenberg.fileids( )[14]\n",
    "print(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112310\n"
     ]
    }
   ],
   "source": [
    "emmatext2 = nltk.corpus.gutenberg.raw(file2)\n",
    "print(len(emmatext2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Tokens and Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book 1\n",
    "emmatokens1 = tknzr.tokenize(emmatext1)\n",
    "emmawords1 = [w.lower( ) for w in emmatokens1] \n",
    "\n",
    "nostop1 = [w for w in emmawords1 if (w not in stopwords)] \n",
    "freqwords1 = [w for w in nostop1 if (w not in string.punctuation)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book 2\n",
    "emmatokens2 = tknzr.tokenize(emmatext2)\n",
    "emmawords2 = [w.lower( ) for w in emmatokens2] \n",
    "\n",
    "nostop2 = [w for w in emmawords2 if (w not in stopwords)] \n",
    "freqwords2 = [w for w in nostop2 if (w not in string.punctuation)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a frequency distribution of words\n",
    "ndist1 = FreqDist(freqwords1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham \t 337\n",
      "lord \t 211\n",
      "haue \t 175\n",
      "king \t 171\n",
      "shall \t 107\n"
     ]
    }
   ],
   "source": [
    "# print the top 30 tokens by frequency\n",
    "nitems1 = ndist1.most_common(5)\n",
    "for item in nitems1:\n",
    "    print (item[0], '\\t', item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have to remove the stop words from Book1 as they have very high frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "total1 = ndist1.N()\n",
    "for word in ndist1:\n",
    "    ndist1[word] /= float(total1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham \t 0.021193635620401233\n"
     ]
    }
   ],
   "source": [
    "# print the top 30 tokens by frequency\n",
    "nitems1 = ndist1.most_common(50)\n",
    "nitems1_df = pd.DataFrame(nitems1, columns=['word', 'freq'])\n",
    "\n",
    "for item in nitems1:\n",
    "    print (item[0], '\\t', item[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>0.021194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lord</td>\n",
       "      <td>0.013270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>haue</td>\n",
       "      <td>0.011006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>king</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shall</td>\n",
       "      <td>0.006729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thou</td>\n",
       "      <td>0.006603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>come</td>\n",
       "      <td>0.006540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hamlet</td>\n",
       "      <td>0.006289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>good</td>\n",
       "      <td>0.006163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hor</td>\n",
       "      <td>0.005974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>let</td>\n",
       "      <td>0.005912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>thy</td>\n",
       "      <td>0.005660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>enter</td>\n",
       "      <td>0.005346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>oh</td>\n",
       "      <td>0.005094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>like</td>\n",
       "      <td>0.004842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>well</td>\n",
       "      <td>0.004402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tis</td>\n",
       "      <td>0.004339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>know</td>\n",
       "      <td>0.004339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>would</td>\n",
       "      <td>0.004276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>selfe</td>\n",
       "      <td>0.004214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>may</td>\n",
       "      <td>0.004088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>loue</td>\n",
       "      <td>0.004088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vs</td>\n",
       "      <td>0.003899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sir</td>\n",
       "      <td>0.003899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qu</td>\n",
       "      <td>0.003899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>laer</td>\n",
       "      <td>0.003773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>giue</td>\n",
       "      <td>0.003710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>thee</td>\n",
       "      <td>0.003648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ile</td>\n",
       "      <td>0.003648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>must</td>\n",
       "      <td>0.003648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hath</td>\n",
       "      <td>0.003585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ophe</td>\n",
       "      <td>0.003522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>speake</td>\n",
       "      <td>0.003459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>make</td>\n",
       "      <td>0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>say</td>\n",
       "      <td>0.003207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>vpon</td>\n",
       "      <td>0.003144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>father</td>\n",
       "      <td>0.003144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>doe</td>\n",
       "      <td>0.003144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>pol</td>\n",
       "      <td>0.003082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>go</td>\n",
       "      <td>0.003019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>one</td>\n",
       "      <td>0.002893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>man</td>\n",
       "      <td>0.002893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>see</td>\n",
       "      <td>0.002830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>heere</td>\n",
       "      <td>0.002830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>time</td>\n",
       "      <td>0.002767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>mine</td>\n",
       "      <td>0.002767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>much</td>\n",
       "      <td>0.002704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>heauen</td>\n",
       "      <td>0.002704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tell</td>\n",
       "      <td>0.002704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>rosin</td>\n",
       "      <td>0.002704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word      freq\n",
       "0      ham  0.021194\n",
       "1     lord  0.013270\n",
       "2     haue  0.011006\n",
       "3     king  0.010754\n",
       "4    shall  0.006729\n",
       "5     thou  0.006603\n",
       "6     come  0.006540\n",
       "7   hamlet  0.006289\n",
       "8     good  0.006163\n",
       "9      hor  0.005974\n",
       "10     let  0.005912\n",
       "11     thy  0.005660\n",
       "12   enter  0.005346\n",
       "13      oh  0.005094\n",
       "14    like  0.004842\n",
       "15    well  0.004402\n",
       "16     tis  0.004339\n",
       "17    know  0.004339\n",
       "18   would  0.004276\n",
       "19   selfe  0.004214\n",
       "20     may  0.004088\n",
       "21    loue  0.004088\n",
       "22      vs  0.003899\n",
       "23     sir  0.003899\n",
       "24      qu  0.003899\n",
       "25    laer  0.003773\n",
       "26    giue  0.003710\n",
       "27    thee  0.003648\n",
       "28     ile  0.003648\n",
       "29    must  0.003648\n",
       "30    hath  0.003585\n",
       "31    ophe  0.003522\n",
       "32  speake  0.003459\n",
       "33    make  0.003396\n",
       "34     say  0.003207\n",
       "35    vpon  0.003144\n",
       "36  father  0.003144\n",
       "37     doe  0.003144\n",
       "38     pol  0.003082\n",
       "39      go  0.003019\n",
       "40     one  0.002893\n",
       "41     man  0.002893\n",
       "42     see  0.002830\n",
       "43   heere  0.002830\n",
       "44    time  0.002767\n",
       "45    mine  0.002767\n",
       "46    much  0.002704\n",
       "47  heauen  0.002704\n",
       "48    tell  0.002704\n",
       "49   rosin  0.002704"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nitems1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a frequency distribution of words\n",
    "ndist2 = FreqDist(freqwords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caesar \t 190\n",
      "brutus \t 161\n",
      "bru \t 153\n",
      "haue \t 147\n",
      "shall \t 125\n"
     ]
    }
   ],
   "source": [
    "# print the top 30 tokens by frequency\n",
    "nitems2 = ndist2.most_common(5)\n",
    "for item in nitems2:\n",
    "    print (item[0], '\\t', item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "total2 = ndist2.N()\n",
    "for word in ndist2:\n",
    "    ndist2[word] /= float(total2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caesar \t 0.017189903193703067\n"
     ]
    }
   ],
   "source": [
    "# print the top 30 tokens by frequency\n",
    "nitems2 = ndist2.most_common(50)\n",
    "nitems2_df = pd.DataFrame(nitems2, columns=['word', 'freq'])\n",
    "\n",
    "for item in nitems2:\n",
    "    print (item[0], '\\t', item[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams and Bigram frequency distribution\n",
    "emmabigrams1 = list(nltk.bigrams(emmawords1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'the', 'tragedie', 'of', 'hamlet']\n",
      "[('[', 'the'), ('the', 'tragedie'), ('tragedie', 'of'), ('of', 'hamlet'), ('hamlet', 'by')]\n"
     ]
    }
   ],
   "source": [
    "print(emmawords1[:5])\n",
    "print(emmabigrams1[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams and Bigram frequency distribution\n",
    "emmabigrams2 = list(nltk.bigrams(emmawords2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'the', 'tragedie', 'of', 'julius']\n",
      "[('[', 'the'), ('the', 'tragedie'), ('tragedie', 'of'), ('of', 'julius'), ('julius', 'caesar')]\n"
     ]
    }
   ],
   "source": [
    "print(emmawords2[:5])\n",
    "print(emmabigrams2[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create FInders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('my', 'lord'), 0.004863002278663925)\n",
      "(('in', 'the'), 0.0020285666648140943)\n",
      "(('to', 'the'), 0.0016673150669704886)\n",
      "(('of', 'the'), 0.0016395264825209803)\n",
      "(('i', 'haue'), 0.0014727949758239316)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder1_raw = BigramCollocationFinder.from_words(emmawords1)\n",
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder1_raw.apply_word_filter(alpha_filter)\n",
    "\n",
    "scored1_raw = finder1_raw.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "for bscore in scored1_raw[:5]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too many the's.. Lets get rid of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('lord', 'ham'), 0.0012226977157783583)\n",
      "(('enter', 'king'), 0.0003334630133940977)\n",
      "(('enter', 'hamlet'), 0.0002778858444950814)\n",
      "(('haue', 'seene'), 0.0002778858444950814)\n",
      "(('lord', 'hamlet'), 0.0002778858444950814)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder1_raw = BigramCollocationFinder.from_words(emmawords1)\n",
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder1_raw.apply_word_filter(alpha_filter)\n",
    "finder1_raw.apply_word_filter(lambda w: w in stopwords)\n",
    "\n",
    "scored1_raw = finder1_raw.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "for bscore in scored1_raw[:5]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to get words longer than two letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('lord', 'ham'), 0.0012226977157783583)\n",
      "(('enter', 'king'), 0.0003334630133940977)\n",
      "(('enter', 'hamlet'), 0.0002778858444950814)\n",
      "(('haue', 'seene'), 0.0002778858444950814)\n",
      "(('lord', 'hamlet'), 0.0002778858444950814)\n",
      "(('good', 'lord'), 0.0002500972600455733)\n",
      "(('thou', 'hast'), 0.0002500972600455733)\n",
      "(('enter', 'polonius'), 0.00022230867559606515)\n",
      "(('fathers', 'death'), 0.00022230867559606515)\n",
      "(('lord', 'polon'), 0.00022230867559606515)\n",
      "(('dost', 'thou'), 0.000194520091146557)\n",
      "(('good', 'friends'), 0.000194520091146557)\n",
      "(('let', 'vs'), 0.000194520091146557)\n",
      "(('haue', 'heard'), 0.00016673150669704886)\n",
      "(('ile', 'haue'), 0.00016673150669704886)\n",
      "(('mine', 'owne'), 0.00016673150669704886)\n",
      "(('thou', 'art'), 0.00016673150669704886)\n",
      "(('enter', 'horatio'), 0.0001389429222475407)\n",
      "(('hamlet', 'ham'), 0.0001389429222475407)\n",
      "(('set', 'downe'), 0.0001389429222475407)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder1_raw = BigramCollocationFinder.from_words(emmawords1)\n",
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder1_raw.apply_word_filter(alpha_filter)\n",
    "finder1_raw.apply_word_filter(lambda w: w in stopwords)\n",
    "finder1_raw.apply_ngram_filter(lambda w1, w2: len(w1) < 3)\n",
    "\n",
    "scored1_raw = finder1_raw.score_ngrams(bigram_measures.raw_freq)\n",
    "scored1_raw_df = pd.DataFrame(scored1_raw, columns=['bigram', 'freq'])\n",
    "\n",
    "for bscore in scored1_raw[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(lord, ham)</td>\n",
       "      <td>0.001223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(enter, king)</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(enter, hamlet)</td>\n",
       "      <td>0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(haue, seene)</td>\n",
       "      <td>0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(lord, hamlet)</td>\n",
       "      <td>0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(good, lord)</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(thou, hast)</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(enter, polonius)</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(fathers, death)</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(lord, polon)</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(dost, thou)</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(good, friends)</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(let, vs)</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(haue, heard)</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(ile, haue)</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(mine, owne)</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(thou, art)</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(enter, horatio)</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(hamlet, ham)</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(set, downe)</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(tell, vs)</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(thy, selfe)</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(wilt, thou)</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(would, haue)</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(come, hither)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(dead, body)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(enter, ghost)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(father, lost)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(get, thee)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(giue, vs)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(good, horatio)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(good, night)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(hath, made)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(let's, follow)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(shall, heare)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(shall, liue)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(sir, ham)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(take, thy)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(thou, shalt)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(thy, soule)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(tis, true)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(would'st, thou)</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(art, thou)</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(christian, buriall)</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(come, againe)</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(come, away)</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(enter, ophelia)</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(enter, queene)</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>(follow, thee)</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>(good, faith)</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  bigram      freq\n",
       "0            (lord, ham)  0.001223\n",
       "1          (enter, king)  0.000333\n",
       "2        (enter, hamlet)  0.000278\n",
       "3          (haue, seene)  0.000278\n",
       "4         (lord, hamlet)  0.000278\n",
       "5           (good, lord)  0.000250\n",
       "6           (thou, hast)  0.000250\n",
       "7      (enter, polonius)  0.000222\n",
       "8       (fathers, death)  0.000222\n",
       "9          (lord, polon)  0.000222\n",
       "10          (dost, thou)  0.000195\n",
       "11       (good, friends)  0.000195\n",
       "12             (let, vs)  0.000195\n",
       "13         (haue, heard)  0.000167\n",
       "14           (ile, haue)  0.000167\n",
       "15          (mine, owne)  0.000167\n",
       "16           (thou, art)  0.000167\n",
       "17      (enter, horatio)  0.000139\n",
       "18         (hamlet, ham)  0.000139\n",
       "19          (set, downe)  0.000139\n",
       "20            (tell, vs)  0.000139\n",
       "21          (thy, selfe)  0.000139\n",
       "22          (wilt, thou)  0.000139\n",
       "23         (would, haue)  0.000139\n",
       "24        (come, hither)  0.000111\n",
       "25          (dead, body)  0.000111\n",
       "26        (enter, ghost)  0.000111\n",
       "27        (father, lost)  0.000111\n",
       "28           (get, thee)  0.000111\n",
       "29            (giue, vs)  0.000111\n",
       "30       (good, horatio)  0.000111\n",
       "31         (good, night)  0.000111\n",
       "32          (hath, made)  0.000111\n",
       "33       (let's, follow)  0.000111\n",
       "34        (shall, heare)  0.000111\n",
       "35         (shall, liue)  0.000111\n",
       "36            (sir, ham)  0.000111\n",
       "37           (take, thy)  0.000111\n",
       "38         (thou, shalt)  0.000111\n",
       "39          (thy, soule)  0.000111\n",
       "40           (tis, true)  0.000111\n",
       "41      (would'st, thou)  0.000111\n",
       "42           (art, thou)  0.000083\n",
       "43  (christian, buriall)  0.000083\n",
       "44        (come, againe)  0.000083\n",
       "45          (come, away)  0.000083\n",
       "46      (enter, ophelia)  0.000083\n",
       "47       (enter, queene)  0.000083\n",
       "48        (follow, thee)  0.000083\n",
       "49         (good, faith)  0.000083"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored1_raw_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information (Min Freq 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('any', 'thing'), 8.72575719277427)\n",
      "(('fathers', 'death'), 8.68393701707964)\n",
      "(('set', 'downe'), 8.297204887020944)\n",
      "(('our', 'selues'), 8.112780315883514)\n",
      "(('dost', 'thou'), 7.768825914666154)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder1_pmi = BigramCollocationFinder.from_words(emmawords1)\n",
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder1_pmi.apply_word_filter(alpha_filter)\n",
    "finder1_pmi.apply_freq_filter(5)\n",
    "# finder1_pmi.apply_word_filter(lambda w: w in stopwords)\n",
    "# finder1_pmi.apply_ngram_filter(lambda w1, w2: len(w1) < 4)\n",
    "\n",
    "scored1_pmi = finder1_pmi.score_ngrams(bigram_measures.pmi)\n",
    "\n",
    "for bscore in scored1_pmi[:5]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of small words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('fathers', 'death'), 8.68393701707964)\n",
      "(('dost', 'thou'), 7.768825914666154)\n",
      "(('wilt', 'thou'), 7.74283070613321)\n",
      "(('enter', 'polonius'), 7.403829097886904)\n",
      "(('mine', 'owne'), 7.306482700608953)\n",
      "(('your', 'lordship'), 7.15215455421766)\n",
      "(('good', 'friends'), 7.079865693410779)\n",
      "(('thou', 'art'), 7.005865111967003)\n",
      "(('thou', 'hast'), 6.835940110524692)\n",
      "(('looke', 'where'), 6.77495945884926)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder1_pmi = BigramCollocationFinder.from_words(emmawords1)\n",
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder1_pmi.apply_word_filter(alpha_filter)\n",
    "finder1_pmi.apply_freq_filter(5)\n",
    "# finder1_pmi.apply_word_filter(lambda w: w in stopwords)\n",
    "finder1_pmi.apply_ngram_filter(lambda w1, w2: len(w1) < 4)\n",
    "\n",
    "scored1_pmi = finder1_pmi.score_ngrams(bigram_measures.pmi)\n",
    "\n",
    "for bscore in scored1_pmi[:10]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too much thou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('fathers', 'death'), 8.68393701707964)\n",
      "(('enter', 'polonius'), 7.403829097886904)\n",
      "(('mine', 'owne'), 7.306482700608953)\n",
      "(('good', 'friends'), 7.079865693410779)\n",
      "(('haue', 'seene'), 6.683937017079643)\n",
      "(('haue', 'heard'), 6.461544595743193)\n",
      "(('tell', 'vs'), 6.076615158710361)\n",
      "(('enter', 'horatio'), 5.725757192774269)\n",
      "(('enter', 'hamlet'), 5.403829097886906)\n",
      "(('lord', 'polon'), 5.166121426761199)\n",
      "(('enter', 'king'), 4.892867178609524)\n",
      "(('lord', 'ham'), 4.476875777660222)\n",
      "(('lord', 'hamlet'), 4.0921208453174245)\n",
      "(('good', 'lord'), 3.969264097531891)\n",
      "(('would', 'haue'), 3.9184022707166655)\n",
      "(('hamlet', 'ham'), 2.4166152528427496)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder1_pmi = BigramCollocationFinder.from_words(emmawords1)\n",
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder1_pmi.apply_word_filter(alpha_filter)\n",
    "finder1_pmi.apply_freq_filter(5)\n",
    "finder1_pmi.apply_word_filter(lambda w: w in stopwords)\n",
    "finder1_pmi.apply_ngram_filter(lambda w1, w2: len(w1) < 4)\n",
    "finder1_pmi.apply_ngram_filter(lambda w1, w2: ((w1 == 'thou') | (w2 == 'thou')))\n",
    "\n",
    "scored1_pmi = finder1_pmi.score_ngrams(bigram_measures.pmi)\n",
    "scored1_pmi_df = pd.DataFrame(scored1_pmi, columns=['bigram', 'freq'])\n",
    "\n",
    "for bscore in scored1_pmi[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(fathers, death)</td>\n",
       "      <td>8.683937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(enter, polonius)</td>\n",
       "      <td>7.403829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(mine, owne)</td>\n",
       "      <td>7.306483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(good, friends)</td>\n",
       "      <td>7.079866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(haue, seene)</td>\n",
       "      <td>6.683937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(haue, heard)</td>\n",
       "      <td>6.461545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(tell, vs)</td>\n",
       "      <td>6.076615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(enter, horatio)</td>\n",
       "      <td>5.725757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(enter, hamlet)</td>\n",
       "      <td>5.403829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(lord, polon)</td>\n",
       "      <td>5.166121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(enter, king)</td>\n",
       "      <td>4.892867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(lord, ham)</td>\n",
       "      <td>4.476876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(lord, hamlet)</td>\n",
       "      <td>4.092121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(good, lord)</td>\n",
       "      <td>3.969264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(would, haue)</td>\n",
       "      <td>3.918402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(hamlet, ham)</td>\n",
       "      <td>2.416615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bigram      freq\n",
       "0    (fathers, death)  8.683937\n",
       "1   (enter, polonius)  7.403829\n",
       "2        (mine, owne)  7.306483\n",
       "3     (good, friends)  7.079866\n",
       "4       (haue, seene)  6.683937\n",
       "5       (haue, heard)  6.461545\n",
       "6          (tell, vs)  6.076615\n",
       "7    (enter, horatio)  5.725757\n",
       "8     (enter, hamlet)  5.403829\n",
       "9       (lord, polon)  5.166121\n",
       "10      (enter, king)  4.892867\n",
       "11        (lord, ham)  4.476876\n",
       "12     (lord, hamlet)  4.092121\n",
       "13       (good, lord)  3.969264\n",
       "14      (would, haue)  3.918402\n",
       "15      (hamlet, ham)  2.416615"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored1_pmi_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('i', 'will'), 0.0020004801152276545)\n",
      "(('i', 'am'), 0.0019204609106185484)\n",
      "(('in', 'the'), 0.0016003840921821237)\n",
      "(('my', 'lord'), 0.0016003840921821237)\n",
      "(('it', 'is'), 0.0014803552852684645)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder2_raw = BigramCollocationFinder.from_words(emmawords2)\n",
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder2_raw.apply_word_filter(alpha_filter)\n",
    "\n",
    "scored2_raw = finder2_raw.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "for bscore in scored2_raw[:5]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('let', 'vs'), 0.0006401536368728495)\n",
      "(('mark', 'antony'), 0.0005201248299591902)\n",
      "(('marke', 'antony'), 0.0004801152276546371)\n",
      "(('thou', 'art'), 0.00044010562535008404)\n",
      "(('art', 'thou'), 0.00036008642074097783)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder2_raw = BigramCollocationFinder.from_words(emmawords2)\n",
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder2_raw.apply_word_filter(alpha_filter)\n",
    "finder2_raw.apply_word_filter(lambda w: w in stopwords)\n",
    "\n",
    "scored2_raw = finder2_raw.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "for bscore in scored2_raw[:5]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to get words longer than two letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('mark', 'antony'), 0.0005201248299591902)\n",
      "(('marke', 'antony'), 0.0004801152276546371)\n",
      "(('thou', 'art'), 0.00044010562535008404)\n",
      "(('enter', 'brutus'), 0.00036008642074097783)\n",
      "(('noble', 'brutus'), 0.00036008642074097783)\n",
      "(('thou', 'hast'), 0.00036008642074097783)\n",
      "(('caesar', 'caes'), 0.00032007681843642473)\n",
      "(('good', 'morrow'), 0.00032007681843642473)\n",
      "(('good', 'night'), 0.00032007681843642473)\n",
      "(('haue', 'done'), 0.00032007681843642473)\n",
      "(('lord', 'bru'), 0.00032007681843642473)\n",
      "(('antony', 'ant'), 0.0002800672161318716)\n",
      "(('enter', 'lucius'), 0.0002800672161318716)\n",
      "(('come', 'downe'), 0.00024005761382731855)\n",
      "(('euery', 'man'), 0.00024005761382731855)\n",
      "(('haue', 'seene'), 0.00024005761382731855)\n",
      "(('would', 'haue'), 0.00024005761382731855)\n",
      "(('caesar', 'shall'), 0.00020004801152276547)\n",
      "(('caius', 'cassius'), 0.00020004801152276547)\n",
      "(('caius', 'ligarius'), 0.00020004801152276547)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder2_raw = BigramCollocationFinder.from_words(emmawords2)\n",
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder2_raw.apply_word_filter(alpha_filter)\n",
    "finder2_raw.apply_word_filter(lambda w: w in stopwords)\n",
    "finder2_raw.apply_ngram_filter(lambda w1, w2: len(w1) < 4)\n",
    "# finder2_pmi.apply_freq_filter(5)\n",
    "\n",
    "scored2_raw = finder2_raw.score_ngrams(bigram_measures.raw_freq)\n",
    "scored2_raw_df = pd.DataFrame(scored2_raw, columns=['bigram', 'freq'])\n",
    "\n",
    "for bscore in scored2_raw[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(mark, antony)</td>\n",
       "      <td>0.00052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(marke, antony)</td>\n",
       "      <td>0.00048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(thou, art)</td>\n",
       "      <td>0.00044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(enter, brutus)</td>\n",
       "      <td>0.00036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(noble, brutus)</td>\n",
       "      <td>0.00036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(thou, hast)</td>\n",
       "      <td>0.00036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(caesar, caes)</td>\n",
       "      <td>0.00032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(good, morrow)</td>\n",
       "      <td>0.00032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(good, night)</td>\n",
       "      <td>0.00032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(haue, done)</td>\n",
       "      <td>0.00032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(lord, bru)</td>\n",
       "      <td>0.00032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(antony, ant)</td>\n",
       "      <td>0.00028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(enter, lucius)</td>\n",
       "      <td>0.00028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(come, downe)</td>\n",
       "      <td>0.00024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(euery, man)</td>\n",
       "      <td>0.00024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(haue, seene)</td>\n",
       "      <td>0.00024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(would, haue)</td>\n",
       "      <td>0.00024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(caesar, shall)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(caius, cassius)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(caius, ligarius)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(decius, brutus)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(did'st, thou)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(enter, antony)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(fell, downe)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(great, caesar)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(haue, beene)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(haue, heard)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(honourable, men)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(metellus, cymber)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(mine, owne)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(shall, finde)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(shall, haue)</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(caesar, doth)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(caesar, hath)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(euery, one)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(heere, comes)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(honourable, man)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(messala, messa)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(mine, eyes)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(noble, antony)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(noble, caesar)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(tell, thee)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(thou, shalt)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(wee'l, heare)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(wilt, thou)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(yong, octauius)</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(brother, cassius)</td>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(brutus, sayes)</td>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>(caesar, lou'd)</td>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>(come, hither)</td>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bigram     freq\n",
       "0       (mark, antony)  0.00052\n",
       "1      (marke, antony)  0.00048\n",
       "2          (thou, art)  0.00044\n",
       "3      (enter, brutus)  0.00036\n",
       "4      (noble, brutus)  0.00036\n",
       "5         (thou, hast)  0.00036\n",
       "6       (caesar, caes)  0.00032\n",
       "7       (good, morrow)  0.00032\n",
       "8        (good, night)  0.00032\n",
       "9         (haue, done)  0.00032\n",
       "10         (lord, bru)  0.00032\n",
       "11       (antony, ant)  0.00028\n",
       "12     (enter, lucius)  0.00028\n",
       "13       (come, downe)  0.00024\n",
       "14        (euery, man)  0.00024\n",
       "15       (haue, seene)  0.00024\n",
       "16       (would, haue)  0.00024\n",
       "17     (caesar, shall)  0.00020\n",
       "18    (caius, cassius)  0.00020\n",
       "19   (caius, ligarius)  0.00020\n",
       "20    (decius, brutus)  0.00020\n",
       "21      (did'st, thou)  0.00020\n",
       "22     (enter, antony)  0.00020\n",
       "23       (fell, downe)  0.00020\n",
       "24     (great, caesar)  0.00020\n",
       "25       (haue, beene)  0.00020\n",
       "26       (haue, heard)  0.00020\n",
       "27   (honourable, men)  0.00020\n",
       "28  (metellus, cymber)  0.00020\n",
       "29        (mine, owne)  0.00020\n",
       "30      (shall, finde)  0.00020\n",
       "31       (shall, haue)  0.00020\n",
       "32      (caesar, doth)  0.00016\n",
       "33      (caesar, hath)  0.00016\n",
       "34        (euery, one)  0.00016\n",
       "35      (heere, comes)  0.00016\n",
       "36   (honourable, man)  0.00016\n",
       "37    (messala, messa)  0.00016\n",
       "38        (mine, eyes)  0.00016\n",
       "39     (noble, antony)  0.00016\n",
       "40     (noble, caesar)  0.00016\n",
       "41        (tell, thee)  0.00016\n",
       "42       (thou, shalt)  0.00016\n",
       "43      (wee'l, heare)  0.00016\n",
       "44        (wilt, thou)  0.00016\n",
       "45    (yong, octauius)  0.00016\n",
       "46  (brother, cassius)  0.00012\n",
       "47     (brutus, sayes)  0.00012\n",
       "48     (caesar, lou'd)  0.00012\n",
       "49      (come, hither)  0.00012"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored2_raw_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information (Min Freq 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('any', 'thing'), 8.72575719277427)\n",
      "(('fathers', 'death'), 8.68393701707964)\n",
      "(('set', 'downe'), 8.297204887020944)\n",
      "(('our', 'selues'), 8.112780315883514)\n",
      "(('dost', 'thou'), 7.768825914666154)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder2_pmi = BigramCollocationFinder.from_words(emmawords2)\n",
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder2_pmi.apply_word_filter(alpha_filter)\n",
    "finder2_pmi.apply_freq_filter(5)\n",
    "# finder2_pmi.apply_word_filter(lambda w: w in stopwords)\n",
    "# finder2_pmi.apply_ngram_filter(lambda w1, w2: len(w1) < 4)\n",
    "\n",
    "scored2_pmi = finder2_pmi.score_ngrams(bigram_measures.pmi)\n",
    "\n",
    "for bscore in scored2_pmi[:5]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of small words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('caius', 'ligarius'), 10.060857561374691)\n",
      "(('metellus', 'cymber'), 10.060857561374691)\n",
      "(('mine', 'owne'), 9.07947323954204)\n",
      "(('fell', 'downe'), 8.822697824179928)\n",
      "(('mark', 'antony'), 8.380475495574851)\n",
      "(('marke', 'antony'), 7.643509901408645)\n",
      "(('good', 'morrow'), 7.573120573517249)\n",
      "(('most', 'noble'), 7.516537045150882)\n",
      "(('what', 'trade'), 7.368979856737022)\n",
      "(('thou', 'hast'), 7.126374214511063)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder2_pmi = BigramCollocationFinder.from_words(emmawords2)\n",
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder2_pmi.apply_word_filter(alpha_filter)\n",
    "finder2_pmi.apply_freq_filter(5)\n",
    "# finder2_pmi.apply_word_filter(lambda w: w in stopwords)\n",
    "finder2_pmi.apply_ngram_filter(lambda w1, w2: len(w1) < 4)\n",
    "\n",
    "scored2_pmi = finder2_pmi.score_ngrams(bigram_measures.pmi)\n",
    "\n",
    "for bscore in scored2_pmi[:10]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('caius', 'ligarius'), 10.060857561374691)\n",
      "(('metellus', 'cymber'), 10.060857561374691)\n",
      "(('mine', 'owne'), 9.07947323954204)\n",
      "(('fell', 'downe'), 8.822697824179928)\n",
      "(('mark', 'antony'), 8.380475495574851)\n",
      "(('marke', 'antony'), 7.643509901408645)\n",
      "(('good', 'morrow'), 7.573120573517249)\n",
      "(('honourable', 'men'), 7.123867358900492)\n",
      "(('haue', 'seene'), 6.994584341955523)\n",
      "(('haue', 'beene'), 6.924195014064127)\n",
      "(('caius', 'cassius'), 6.821391626679302)\n",
      "(('enter', 'lucius'), 6.7162093899872435)\n",
      "(('euery', 'man'), 6.605542051209625)\n",
      "(('haue', 'heard'), 6.561624934679418)\n",
      "(('come', 'downe'), 6.461241365105925)\n",
      "(('good', 'night'), 6.232083655682182)\n",
      "(('haue', 'done'), 5.886059885177357)\n",
      "(('shall', 'finde'), 5.87797515504567)\n",
      "(('antony', 'ant'), 5.602867916911299)\n",
      "(('decius', 'brutus'), 5.512842561593139)\n",
      "(('noble', 'brutus'), 5.162900090536178)\n",
      "(('lord', 'bru'), 4.892474724740785)\n",
      "(('caesar', 'caes'), 4.7540363588775385)\n",
      "(('enter', 'antony'), 4.702403590462215)\n",
      "(('great', 'caesar'), 4.6609269544860545)\n",
      "(('would', 'haue'), 4.535152723318227)\n",
      "(('enter', 'brutus'), 4.448302309398425)\n",
      "(('shall', 'haue'), 2.7657656514596454)\n",
      "(('caesar', 'shall'), 2.39558238796506)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder2_pmi = BigramCollocationFinder.from_words(emmawords2)\n",
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder2_pmi.apply_word_filter(alpha_filter)\n",
    "finder2_pmi.apply_freq_filter(5)\n",
    "finder2_pmi.apply_word_filter(lambda w: w in stopwords)\n",
    "finder2_pmi.apply_ngram_filter(lambda w1, w2: len(w1) < 4)\n",
    "finder2_pmi.apply_ngram_filter(lambda w1, w2: ((w1 == 'thou') | (w2 == 'thou')))\n",
    "\n",
    "\n",
    "scored2_pmi = finder2_pmi.score_ngrams(bigram_measures.pmi)\n",
    "scored2_pmi_df = pd.DataFrame(scored2_pmi, columns=['bigram', 'freq'])\n",
    "\n",
    "for bscore in scored2_pmi[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(caius, ligarius)</td>\n",
       "      <td>10.060858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(metellus, cymber)</td>\n",
       "      <td>10.060858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(mine, owne)</td>\n",
       "      <td>9.079473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(fell, downe)</td>\n",
       "      <td>8.822698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(mark, antony)</td>\n",
       "      <td>8.380475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(marke, antony)</td>\n",
       "      <td>7.643510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(good, morrow)</td>\n",
       "      <td>7.573121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(honourable, men)</td>\n",
       "      <td>7.123867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(haue, seene)</td>\n",
       "      <td>6.994584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(haue, beene)</td>\n",
       "      <td>6.924195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(caius, cassius)</td>\n",
       "      <td>6.821392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(enter, lucius)</td>\n",
       "      <td>6.716209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(euery, man)</td>\n",
       "      <td>6.605542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(haue, heard)</td>\n",
       "      <td>6.561625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(come, downe)</td>\n",
       "      <td>6.461241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(good, night)</td>\n",
       "      <td>6.232084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(haue, done)</td>\n",
       "      <td>5.886060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(shall, finde)</td>\n",
       "      <td>5.877975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(antony, ant)</td>\n",
       "      <td>5.602868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(decius, brutus)</td>\n",
       "      <td>5.512843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(noble, brutus)</td>\n",
       "      <td>5.162900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(lord, bru)</td>\n",
       "      <td>4.892475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(caesar, caes)</td>\n",
       "      <td>4.754036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(enter, antony)</td>\n",
       "      <td>4.702404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(great, caesar)</td>\n",
       "      <td>4.660927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(would, haue)</td>\n",
       "      <td>4.535153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(enter, brutus)</td>\n",
       "      <td>4.448302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(shall, haue)</td>\n",
       "      <td>2.765766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(caesar, shall)</td>\n",
       "      <td>2.395582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bigram       freq\n",
       "0    (caius, ligarius)  10.060858\n",
       "1   (metellus, cymber)  10.060858\n",
       "2         (mine, owne)   9.079473\n",
       "3        (fell, downe)   8.822698\n",
       "4       (mark, antony)   8.380475\n",
       "5      (marke, antony)   7.643510\n",
       "6       (good, morrow)   7.573121\n",
       "7    (honourable, men)   7.123867\n",
       "8        (haue, seene)   6.994584\n",
       "9        (haue, beene)   6.924195\n",
       "10    (caius, cassius)   6.821392\n",
       "11     (enter, lucius)   6.716209\n",
       "12        (euery, man)   6.605542\n",
       "13       (haue, heard)   6.561625\n",
       "14       (come, downe)   6.461241\n",
       "15       (good, night)   6.232084\n",
       "16        (haue, done)   5.886060\n",
       "17      (shall, finde)   5.877975\n",
       "18       (antony, ant)   5.602868\n",
       "19    (decius, brutus)   5.512843\n",
       "20     (noble, brutus)   5.162900\n",
       "21         (lord, bru)   4.892475\n",
       "22      (caesar, caes)   4.754036\n",
       "23     (enter, antony)   4.702404\n",
       "24     (great, caesar)   4.660927\n",
       "25       (would, haue)   4.535153\n",
       "26     (enter, brutus)   4.448302\n",
       "27       (shall, haue)   2.765766\n",
       "28     (caesar, shall)   2.395582"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored2_pmi_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
